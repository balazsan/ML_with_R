{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=5>Bonus exercise if time allows</font>\n",
    "\n",
    "<font size=4>The bonus exercise is to a high extent identical to the previous one. The only difference is that to overcome the issue of overfitting additionally to early stopping we will see how to save the best model during training.<br>Without saving the best model during training (i.e. the one that had the lowest validation loss in our case), it is going to be trained <b>n</b> times (n=number of epochs used as the [patience parameter](03_Exercise.ipynb#patience)) after it actually reached the best performance. In other words early stopping means that the validation loss is being monitored (saved for each epoch) and if the loss is not getting smaller e.g. during the next 20 epochs (n or patience=20) stop the training. The problem with this is that the model has been trained already 20 times after the best validation loss was achieved, therefore it is very likely that the resulting model won't be as good as 20 epochs earlier.<br>To help solve this issue we are going to save the best model during the training period (still using early stopping).<br><br>The first part of the script we are going to run in one batch. It is the same as previously apart from unnecessary printing of information like.</font>\n",
    "```R\n",
    "head(feat.train,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 1.\n",
    "###########################################################\n",
    "############ IMPORTING AND PRE-PROCESSING DATA ############\n",
    "###########################################################\n",
    "\n",
    "# loading sample plot information based on field observations\n",
    "# each column represents some sample plot specific information and each row a sample plot\n",
    "# we are interested in the columns \"v\", \"h\" and \"d\" (total growing stock, mean height and mean diamater)\n",
    "\n",
    "# training data (the Neural Network (NN) will be trained with this dataset)\n",
    "sp.data.train <- read.csv(\"../data/AV.leaf.on.train.csv\",as.is=T)\n",
    "# validation data (this dataset helps to avoid overfitting during training)\n",
    "sp.data.val <- read.csv(\"../data/AV.leaf.on.val.csv\",as.is=T)\n",
    "# test data (this dataset is used to evaluate the trained NN on data that is unknown to the NN)\n",
    "sp.data.test <- read.csv(\"../data/AV.leaf.on.test.csv\",as.is=T)\n",
    "\n",
    "# loading remote sensing features calculated for each sample plot from LiDAR (laser) data\n",
    "# each column (apart from the sample plot ID) represents a feature and each row a sample plot\n",
    "\n",
    "# importing LiDAR features for the entire data (training, validation and test)\n",
    "feat <- readRDS(\"../data/las.feat.AV-MK.leaf.on.RDS\")\n",
    "\n",
    "# separating the features into training, validation and test sets based on the sample plot IDs of\n",
    "# sample plot information imoprted above\n",
    "feat.train <- feat[feat$sampleplotid%in%sp.data.train$sampleplotid,]\n",
    "feat.val <- feat[feat$sampleplotid%in%sp.data.val$sampleplotid,]\n",
    "feat.test <- feat[feat$sampleplotid%in%sp.data.test$sampleplotid,]\n",
    "\n",
    "# pre-processing feature data\n",
    "\n",
    "# at this point the column of sample plot ID can be removed\n",
    "feat.train$sampleplotid <- NULL; feat.val$sampleplotid <- NULL; feat.test$sampleplotid <- NULL\n",
    "\n",
    "# some of the features (columns) might have no variation (same value is repeated in every row)\n",
    "# such information is not helpful and should be removed (standard deviation is 0 or NaN/NA)\n",
    "orig.nfeat <- ncol(feat.train)\n",
    "feat.train <- feat.train[,apply(feat.train,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "feat.val <- feat.val[,apply(feat.val,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "feat.test <- feat.test[,apply(feat.test,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "\n",
    "# keeping only those features that are present in all 3 datsets\n",
    "# extracting column names common in all 3 sets\n",
    "feat.common <- Reduce(intersect,list(names(feat.train),names(feat.val),names(feat.test)))\n",
    "# subsetting datasets\n",
    "feat.train <- feat.train[,feat.common]\n",
    "feat.val <- feat.val[,feat.common]\n",
    "feat.test <- feat.test[,feat.common]; rm(feat.common)\n",
    "\n",
    "# scaling is done so that after scaling each column's mean equals 0 and standard deviation equals 1\n",
    "# the attributes \"center\" and \"scale\" of the training set is going to be used to scale the validation and test sets\n",
    "# \"center\" is the mean and \"scale\" is the standard deviation of each column in the training data\n",
    "train.data <- scale(feat.train)\n",
    "mean.train <- attr(train.data,\"scaled:center\")\n",
    "sd.train <- attr(train.data,\"scaled:scale\")\n",
    "val.data <- scale(feat.val,center=mean.train,scale=sd.train)\n",
    "test.data <- scale(feat.test,center=mean.train,scale=sd.train)\n",
    "\n",
    "# pre-processing sample plot data\n",
    "\n",
    "# creating variable for forest attributes we are going to use\n",
    "for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "\n",
    "# selecting columns\n",
    "sp.data.train <- sp.data.train[,for.attrs]\n",
    "sp.data.val <- sp.data.val[,for.attrs]\n",
    "sp.data.test <- sp.data.test[,for.attrs]\n",
    "\n",
    "# scaling data the same way as above\n",
    "train.labels <- scale(sp.data.train)\n",
    "mean.train <- attr(train.labels,\"scaled:center\")\n",
    "sd.train <- attr(train.labels,\"scaled:scale\")\n",
    "# Keras' fit function doesn't accept the output of scale() for labels, it needs to be converted to data frame\n",
    "val.labels <- as.data.frame(scale(sp.data.val,center=mean.train,scale=sd.train))\n",
    "test.labels <- as.data.frame(scale(sp.data.test,center=mean.train,scale=sd.train))\n",
    "train.labels <- as.data.frame(train.labels)\n",
    "\n",
    "###########################################################\n",
    "############ CREATING AND TRAINING THE NETWORK ############\n",
    "###########################################################\n",
    "\n",
    "# loading keras library\n",
    "library(keras)\n",
    "\n",
    "# loading custom functions stored in a separate R script (ML_with_R/functions/keras_tf_funcs.R)\n",
    "source(\"../functions/keras_tf_funcs.R\")\n",
    "\n",
    "# setting the number of neurons in the hidden layer\n",
    "# uncomment the line(s) that you want to use (don't uncomment lines starting with # #)\n",
    "\n",
    "# # Ns/(a*(Ni+No)) (Ns: number of samples; a: scaling factor (2-10);\n",
    "# # Ni: number of input neurons (features); No: number of output neurons (dependent variables))\n",
    "# a <- 2\n",
    "# n.neur <- ceiling(nrow(train.data)/(a*(ncol(train.data)+ncol(train.labels))))\n",
    "# paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # number of neurons of hidden layer can be Ni*2/3+No\n",
    "# n.neur <- ceiling(ncol(train.data)*(2/3)+ncol(train.labels))\n",
    "# paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # number of neurons of hidden layer can be (Ni+No)/2\n",
    "# n.neur <- ceiling((ncol(train.data)+ncol(train.labels))/2)\n",
    "# paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # set the number of neurons to any value you'd like to test\n",
    "# # (too big values (over 200) will slow down the training process!)\n",
    "n.neur <- 6\n",
    "\n",
    "# designing the network\n",
    "\n",
    "# creating input layer; the shape parameter has to be set\n",
    "# to the number of columns (number of features) in the feature table (see cell 4.)\n",
    "inputs <- layer_input(shape=ncol(train.data))\n",
    "\n",
    "# creating network structure\n",
    "# we are going to calculate predictions for multiple forest attributes (v, h, d)\n",
    "for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "# therefore we are iterating through these attribute names and adding them one-by-one to the network\n",
    "preds <- lapply(for.attrs,function(for.attr) {\n",
    "  inputs %>%\n",
    "    # adding hidden layer\n",
    "    # number of units: this parameter should be tested with different values\n",
    "    # activation: different activation functions can be tested\n",
    "    #             for in-built functions use function name in quotes (e.g. \"relu\", \"elu\")\n",
    "    #             for custom functions use function name without quotes (e.g. swish_activation)\n",
    "    layer_dense(units=n.neur,activation=\"relu\") %>%\n",
    "    # layer_dense(units=n.neur,activation=swish_activation) %>%\n",
    "    # adding output layer (number of units 1 as output is one value for each attribute)\n",
    "    layer_dense(units=1,name=for.attr)\n",
    "})\n",
    "\n",
    "# creating the model\n",
    "tf.model <- keras_model(inputs=inputs,outputs=preds)\n",
    "\n",
    "# finalizing and configuring the model\n",
    "# some parameters for configuration:\n",
    "\n",
    "# weights for forest attributes\n",
    "# here we can set how much each forest attribute is affecting the overall accuracy score\n",
    "# the order is the same as for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "# can be experimented with (e.g. c(0.7,0.15,0.15))\n",
    "preds.w <- c(0.6,0.2,0.2)\n",
    "\n",
    "# the optimizer function to be used (see the Optimizers section of 02_Simple_Neural_Networks)\n",
    "# (for further options go to https://keras.rstudio.com/reference/index.html#section-optimizers)\n",
    "opt <- \"adam\"\n",
    "# opt <- \"rmsprop\"\n",
    "\n",
    "# loss function to be used (see the Loss section of 02_Simple_Neural_Networks)\n",
    "# (for further options go to https://keras.rstudio.com/reference/index.html#section-losses)\n",
    "# Mean Squared Error is considered to be a good choice for regression problems and shouldn't be changed\n",
    "loss <- \"mean_squared_error\"\n",
    "\n",
    "# compiling the model\n",
    "tf.model %>% compile(\n",
    "  optimizer=opt,\n",
    "  loss=loss,\n",
    "  loss_weights=preds.w,\n",
    ")\n",
    "\n",
    "# parameters for fit function\n",
    "batch_size=25\n",
    "patience=20\n",
    "epochs=200\n",
    "\n",
    "# setting up early stopping against overfitting\n",
    "early.stop <- callback_early_stopping(monitor=\"val_loss\",patience=patience)\n",
    "\n",
    "# printing parameters used during model training\n",
    "paste0(\"Number of neurons: \",n.neur)\n",
    "paste0(\"Weights for forest attributes (v, h, d): \",paste0(preds.w,collapse=\", \"))\n",
    "paste0(\"Optimizaiton function used: \",opt)\n",
    "paste0(\"Batch size used: \",batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>In the next cell we will create the function that saves the best model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2.\n",
    "# first creating the output file name for the model\n",
    "# out.name will make it possible to save best models for various parameter combinations\n",
    "# set it to reflect the parameters that have been used to train the model (see cell 14. in 03_Exercise.ipynb)\n",
    "out.name <- \"adam_swish_bs25_6.2.2\"\n",
    "# out.name <- \"adam_relu_bs25_6.2.2\"\n",
    "filepath <- paste0(\"best.model.\",out.name,\".hdf5\")\n",
    "\n",
    "# creating checkpoint callback\n",
    "# model saved after each epoch if the validation loss is smaller than the previous one\n",
    "# save_weights_only: saving the full model if true\n",
    "# mode: the target is to minimize validation loss\n",
    "cp_callback <- callback_model_checkpoint(\n",
    "  filepath=filepath,monitor=\"val_loss\",\n",
    "  save_weights_only=F,save_best_only=T,\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "# fit the model (same as train the model)\n",
    "# note that the model saving function is added to the parameter callbacks\n",
    "history <- fit(object=tf.model,x=train.data,y=train.labels,batch_size=batch_size,\n",
    "               epochs=epochs,validation_data=list(val.data,val.labels),\n",
    "               verbose=2,callbacks=list(early.stop,cp_callback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3.\n",
    "\n",
    "# plotting the training history\n",
    "# right click on the picture and select \"Open image in new tab\"\n",
    "# the number of epochs needs to be fixed when early stopping is used\n",
    "history$params$epochs <- length(history$metrics$loss)\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Now we are going to load the saved best model and calculate its performance for training, validation and test datasets.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4.\n",
    "# calculating error estimates, evaluating model performance\n",
    "\n",
    "# file name of best model\n",
    "best.model.name <- paste0(\"best.model.\",out.name,\".hdf5\")\n",
    "\n",
    "# loading the model\n",
    "# if you have used a custom object (e.g. swish_activation) use the custom_objects parameter\n",
    "# if you haven't used any custom objects the custom_objects parameter will be ignored\n",
    "best.model <- load_model_hdf5(best.model.name,custom_objects=c(\"python_function\"=swish_activation))\n",
    "\n",
    "# calculating predictions with the trained model\n",
    "train.predictions <- best.model %>% predict(train.data); train.predictions <- as.data.frame(Reduce(cbind,train.predictions))\n",
    "val.predictions <- best.model %>% predict(val.data); val.predictions <- as.data.frame(Reduce(cbind,val.predictions))\n",
    "test.predictions <- best.model %>% predict(test.data); test.predictions <- as.data.frame(Reduce(cbind,test.predictions))\n",
    "\n",
    "# de-scaling predictions (when forest attribute data is scaled in the model, the predictions are\n",
    "# going to be scaled as well and need to be de-scaled using the same method used for scaling the \n",
    "# original forest attributes)\n",
    "train.predictions <- sapply(1:ncol(train.predictions),function(i) (train.predictions[i]*sd.train[i])+mean.train[i])\n",
    "train.predictions <- as.data.frame(do.call(cbind,train.predictions))\n",
    "\n",
    "val.predictions <- sapply(1:ncol(val.predictions),function(i) (val.predictions[i]*sd.train[i])+mean.train[i])\n",
    "val.predictions <- as.data.frame(do.call(cbind,val.predictions))\n",
    "\n",
    "test.predictions <- sapply(1:ncol(test.predictions),function(i) (test.predictions[i]*sd.train[i])+mean.train[i])\n",
    "test.predictions <- as.data.frame(do.call(cbind,test.predictions))\n",
    "\n",
    "# calculating relative RMSE and bias for all datasets using predifened functions (see cell 6.)\n",
    "train.rmse <- rel.rmse(sp.data.train,train.predictions)\n",
    "train.bias <- rel.bias(sp.data.train,train.predictions)\n",
    "\n",
    "val.rmse <- rel.rmse(sp.data.val,val.predictions)\n",
    "val.bias <- rel.bias(sp.data.val,val.predictions)\n",
    "\n",
    "test.rmse <- rel.rmse(sp.data.test,test.predictions)\n",
    "test.bias <- rel.bias(sp.data.test,test.predictions)\n",
    "\n",
    "# printing results\n",
    "results <- rbind(train.rmse,val.rmse,test.rmse)\n",
    "row.names(results) <- c(\"training RMSE %\",\"validation RMSE %\",\"test RMSE %\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Save the results to compare them to other results of this exercise and/or to the results of the previous notebook. One interesting option is to run the training with the same parameter combination in both notebooks and compare the results. Are the results of the bonus exercise in deed better than the others? Bear in mind that randomness might also influence the results.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Let's clean up after the training is done, results and model is saved. Without doing so errors might occur during consecutive trainings.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5.\n",
    "\n",
    "# let's clean up after training; if this is not done errors will occur\n",
    "# when you try to start building and training a new model\n",
    "rm(tf.model,best.model,best.model.name)\n",
    "k_clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=5><b>Exercise</b></font><br><br>\n",
    "\n",
    "<font size=4>Just like in the previous exercise you can try different parameter combinations (don't forget to change ```out.name``` in cell 2.!). Compare the results of this exercise between each other and also to the results of the previous notebook.</font><br>\n",
    "<font size=4>Try out different options for some parameters (optimization and activation function, number of neurons in the hidden layer, batch size, weights for forest attributes, number of epochs). Best practice is to change one parameter at the time, compare the results to the previous ones and so on.<br><b>In order to enable line numbering in Code cells go to View > Toggle Line Numbers.</b></font><br>\n",
    "\n",
    "* <font size=4>Go back to cell 1./lines 87-106 and try other options for number of neurons in the hidden layer</font><br><br>\n",
    "* <font size=4>Go back to 1./lines 125-126 and try RELU activation (you can also try \"elu\" instead of \"relu\")</font>\n",
    "```R\n",
    "layer_dense(units=n.neur,activation=\"relu\") %>%\n",
    "# layer_dense(units=n.neur,activation=swish_activation) %>%\n",
    "```\n",
    "* <font size=4>Go back to cell 1./lines 140-141 and try another set of weights for forest attributes</font>\n",
    "```R\n",
    "# can be experimented with (e.g. c(0.7,0.15,0.15))\n",
    "preds.w <- c(0.7,0.15,0.15)\n",
    "```\n",
    "* <font size=4>Go back to cell 1./lines 145-146 and try some other optimizer function</font>\n",
    "```R\n",
    "# opt <- \"adam\"\n",
    "opt <- \"rmsprop\"\n",
    "```\n",
    "* <font size=4>Go back to cell 1./lines 161-163 and try some other options for <b>batch size</b> (shouldn't be set to more than 1044 that is the number of samples in the training data), <b>number of epochs</b> (the bigger number the longer the training will run), <b>patience</b> (you can also try to set it to the same value as the number of epochs; this way no early stopping is done)</font>\n",
    "```R\n",
    "# parameters for fit function\n",
    "batch_size=25\n",
    "patience=20\n",
    "epochs=200\n",
    "```\n",
    "\n",
    "<font size=4><b>Remember to change the file name for your new model in cell 2./line 5, otherwise the already existing file will be replaced!</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
