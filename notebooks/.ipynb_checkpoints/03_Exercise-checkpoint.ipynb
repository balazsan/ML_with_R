{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=5>Application of simple Neural Network in forest inventory</font>\n",
    "\n",
    "<font size=4>This exercise is showing how a fully connected shallow neural network ca be used to estimate forest attributes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1.\n",
    "###########################################################\n",
    "############ IMPORTING AND PRE-PROCESSING DATA ############\n",
    "###########################################################\n",
    "\n",
    "# loading sample plot information based on field observations\n",
    "# each column represents some sample plot specific information and each row a sample plot\n",
    "# we are interested in the columns \"v\", \"h\" and \"d\" (total growing stock, mean height and mean diamater)\n",
    "\n",
    "# training data (the Neural Network (NN) will be trained with this dataset)\n",
    "sp.data.train <- read.csv(\"../data/AV.leaf.on.train.csv\",as.is=T)\n",
    "# validation data (this dataset helps to avoid overfitting during training)\n",
    "sp.data.val <- read.csv(\"../data/AV.leaf.on.val.csv\",as.is=T)\n",
    "# test data (this dataset is used to evaluate the trained NN on data that is unknown to the NN)\n",
    "sp.data.test <- read.csv(\"../data/AV.leaf.on.test.csv\",as.is=T)\n",
    "\n",
    "# checking data structure (all 3 datasets have the same columns)\n",
    "head(sp.data.train,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Note that the value range of column \"v\" compared to \"h\" and \"d\" is different, scaling of data is necessary!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2.\n",
    "# loading remote sensing features calculated for each sample plot from LiDAR (laser) data\n",
    "# each column (apart from the sample plot ID) represents a feature and each row a sample plot\n",
    "\n",
    "# importing LiDAR features for the entire data (training, validation and test)\n",
    "feat <- readRDS(\"../data/las.feat.AV-MK.leaf.on.RDS\")\n",
    "\n",
    "# separating the features into training, validation and test sets based on the sample plot IDs of\n",
    "# sample plot information imoprted above\n",
    "feat.train <- feat[feat$sampleplotid%in%sp.data.train$sampleplotid,]\n",
    "feat.val <- feat[feat$sampleplotid%in%sp.data.val$sampleplotid,]\n",
    "feat.test <- feat[feat$sampleplotid%in%sp.data.test$sampleplotid,]\n",
    "\n",
    "# checking data structure (all 3 datasets have the same columns)\n",
    "head(feat.train,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Note that sample plot IDs in both tables are the same!<br>\n",
    "Note also that the value range of different columns varies a lot, scaling of data is necessary!</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 3.\n",
    "# pre-processing feature data\n",
    "\n",
    "# at this point the column of sample plot ID can be removed\n",
    "feat.train$sampleplotid <- NULL; feat.val$sampleplotid <- NULL; feat.test$sampleplotid <- NULL\n",
    "\n",
    "# some of the features (columns) might have no variation (same value is repeated in every row)\n",
    "# such information is not helpful and should be removed (standard deviation is 0 or NaN/NA)\n",
    "orig.nfeat <- ncol(feat.train)\n",
    "feat.train <- feat.train[,apply(feat.train,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "feat.val <- feat.val[,apply(feat.val,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "feat.test <- feat.test[,apply(feat.test,2,function(x) !(sd(x)==0|is.na(sd(x))))]\n",
    "\n",
    "# keeping only those features that are present in all 3 datsets\n",
    "# extracting column names common in all 3 sets\n",
    "feat.common <- Reduce(intersect,list(names(feat.train),names(feat.val),names(feat.test)))\n",
    "# subsetting datasets\n",
    "feat.train <- feat.train[,feat.common]\n",
    "feat.val <- feat.val[,feat.common]\n",
    "feat.test <- feat.test[,feat.common]; rm(feat.common)\n",
    "\n",
    "print(paste0(\"Number of features originally: \",orig.nfeat))\n",
    "print(paste0(\"Number of features after processing: \",ncol(feat.train)))\n",
    "print(paste0(\"Number of features removed: \",orig.nfeat-(ncol(feat.train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>As mentioned before, scaling of sample plot and feature data is necessary. \"Unscaled input variables can result in a slow or unstable learning process, whereas unscaled target variables on regression problems can result in exploding gradients causing the learning process to fail.\"<br>\n",
    "For more information see:<br></font>\n",
    "https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4.\n",
    "# scaling is done so that after scaling each column's mean equals 0 and standard deviation equals 1\n",
    "# the attributes \"center\" and \"scale\" of the training set is going to be used to scale the validation and test sets\n",
    "# \"center\" is the mean and \"scale\" is the standard deviation of each column in the training data\n",
    "train.data <- scale(feat.train)\n",
    "mean.train <- attr(train.data,\"scaled:center\")\n",
    "sd.train <- attr(train.data,\"scaled:scale\")\n",
    "val.data <- scale(feat.val,center=mean.train,scale=sd.train)\n",
    "test.data <- scale(feat.test,center=mean.train,scale=sd.train)\n",
    "\n",
    "# compare the scaled table with the one in Cell 2.\n",
    "cat(\"original feature data\")\n",
    "head(feat.train,2)\n",
    "cat(\"scaled feature data\")\n",
    "head(train.data,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5.\n",
    "# pre-processing sample plot data\n",
    "\n",
    "# creating variable for forest attributes we are going to use\n",
    "for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "\n",
    "# selecting columns\n",
    "sp.data.train <- sp.data.train[,for.attrs]\n",
    "sp.data.val <- sp.data.val[,for.attrs]\n",
    "sp.data.test <- sp.data.test[,for.attrs]\n",
    "\n",
    "# scaling data the same way as above\n",
    "train.labels <- scale(sp.data.train)\n",
    "mean.train <- attr(train.labels,\"scaled:center\")\n",
    "sd.train <- attr(train.labels,\"scaled:scale\")\n",
    "# Keras' fit function doesn't accept the output of scale() for labels, it needs to be converted to data frame\n",
    "val.labels <- as.data.frame(scale(sp.data.val,center=mean.train,scale=sd.train))\n",
    "test.labels <- as.data.frame(scale(sp.data.test,center=mean.train,scale=sd.train))\n",
    "train.labels <- as.data.frame(train.labels)\n",
    "\n",
    "# compare the scaled table with the one in Cell 1.\n",
    "cat(\"original sample plot data\")\n",
    "head(sp.data.train,2)\n",
    "cat(\"scaled sample plot data\")\n",
    "head(train.labels,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>In the following cell we will start to construct our Neural Network. It is recommended to open the notebook with information on [Simple Neural Networks](02_Simple_Neural_Networks.ipynb) if not opened. Check for explanations there if necessary.<br>From here on the tables containing feature information are called \"data\" and tables with forest attributes called \"labels\". Input data is used to make predictions and labels are used to check the accuracy of predicted values.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6.\n",
    "###########################################################\n",
    "############ CREATING AND TRAINING THE NETWORK ############\n",
    "###########################################################\n",
    "\n",
    "# loading keras library\n",
    "library(keras)\n",
    "\n",
    "# loading custom functions stored in a separate R script (ML_with_R/functions/keras_tf_funcs.R)\n",
    "source(\"../functions/keras_tf_funcs.R\")\n",
    "# printing names of imported functions\n",
    "cat(\"Imported functions:\",paste0(as.vector(lsf.str()),collapse=\", \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "* <font size=4>rel.bias: calculating relative bias (underestimation gives negative bias)</font>\n",
    "* <font size=4>rel.rmse: calculating relative Root Mean Squared Error</font>\n",
    "* <font size=4>swish_activation: custom activation function used in the network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>In the next cells we are going to design the network using the following parameters:</font>\n",
    "* <font size=4><b>batch_size</b>: the amount of <font size=4 color='red'>red circles</font> in the [input layer](02_Simple_Neural_Networks.ipynb#graph) depends on how many sample plots (rows) of the data we are feeding into the training process. This value is called batch size. The batch size usually has an effect on the performance of the network and should also be tested with various values. A standard value widely used is 32.</font>\n",
    "* <font size=4><b>shape</b>: used in creating the input layer, corresponds to the number of columns (features) to be used during training. The shape defines the dimension of each <font><font size=4 color='red'>red circle</font><font size=4> in the input layer of the graph.</font>\n",
    "* <font size=4><b>units</b>: the number of neurons used in the hidden layer. This parameter can and should be \"tuned\": we are going to try different values and check which gives us the best performance. This value determines the amount of <font><font size=4 color='blue'>blue circles</font><font size=4> in the hidden layer of the graph.<br>There is no consensus about what is the optimal value for this parameter. In the <b>Hidden layers</b> section of this [StackExchange answer](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw) there are several suggestions and further links.</font>\n",
    "* <font size=4><b>activation</b>: used in the hidden layer. This function determines how the input data is transformed in the neurons of the hidden layer. There are in-built [activation functions](https://keras.rstudio.com/reference/index.html#section-activations) but it is also possible to create custom functions. We are going to test different activation functions.</font>\n",
    "* <font size=4>The amount of <font size=4 color='green'>green circles</font> of the output layer depends in our case on how many forest attributes (dependent variables) are included in the process (3 in this exercise).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7.\n",
    "\n",
    "# setting the number of neurons in the hidden layer\n",
    "# uncomment the line(s) that you want to use (don't uncomment lines starting with # #)\n",
    "\n",
    "# # Ns/(a*(Ni+No)) (Ns: number of samples; a: scaling factor (2-10);\n",
    "# # Ni: number of input neurons (features); No: number of output neurons (dependent variables))\n",
    "# a <- 2\n",
    "# n.neur <- ceiling(nrow(train.data)/(a*(ncol(train.data)+ncol(train.labels))))\n",
    "# paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # number of neurons of hidden layer can be Ni*2/3+No\n",
    "# n.neur <- ceiling(ncol(train.data)*(2/3)+ncol(train.labels))\n",
    "# paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # number of neurons of hidden layer can be (Ni+No)/2\n",
    "n.neur <- ceiling((ncol(train.data)+ncol(train.labels))/2)\n",
    "paste0(\"Number of neurons: \",n.neur)\n",
    "\n",
    "# # set the number of neurons to any value you'd like to test\n",
    "# # (too big values (over 200) will slow down the training process!)\n",
    "# n.neur <- 6\n",
    "# paste0(\"Number of neurons: \",n.neur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 8.\n",
    "# designing the network\n",
    "\n",
    "# creating input layer; the shape parameter has to be set\n",
    "# to the number of columns (number of features) in the feature table (see cell 4.)\n",
    "inputs <- layer_input(shape=ncol(train.data))\n",
    "\n",
    "# creating network structure\n",
    "# we are going to calculate predictions for multiple forest attributes (v, h, d)\n",
    "for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "# therefore we are iterating through these attribute names and adding them one-by-one to the network\n",
    "preds <- lapply(for.attrs,function(for.attr) {\n",
    "  inputs %>%\n",
    "    # adding hidden layer\n",
    "    # number of units: this parameter should be tested with different values\n",
    "    # activation: different activation functions can be tested\n",
    "    #             for in-built functions use function name in quotes (e.g. \"relu\", \"elu\")\n",
    "    #             for custom functions use function name without quotes (e.g. swish_activation)\n",
    "    # layer_dense(units=n.neur,activation=\"relu\") %>%\n",
    "    layer_dense(units=n.neur,activation=swish_activation) %>%\n",
    "    # adding output layer (number of units 1 as output is one value for each attribute)\n",
    "    layer_dense(units=1,name=for.attr)\n",
    "})\n",
    "\n",
    "cat(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 9.\n",
    "\n",
    "# creating the model\n",
    "tf.model <- keras_model(inputs=inputs,outputs=preds)\n",
    "# printing summary\n",
    "summary(tf.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "* <font size=4>For each forest attribute a hidden and an output layer is created.</font>\n",
    "* <font size=4>All layers have dimensions (None,190/6/1). None means the layer can take any data that meets the second dimension criteria (e.g. various number of rows of feature table (which has 190 columns)). \"None\" actually refers to the batch size, which can be set to an arbitrary value between 1 and the amount of samples in the training data.</font>\n",
    "* <font size=4>Number of parameters are defined as follows:</font>\n",
    "    * <font size=4>the input layer has no parameters as it is just taking the input data</font>\n",
    "    * <font size=4>hidden layers have 190x6=1140 as input and 6 as output, a total of 1146</font>\n",
    "    * <font size=4>output layers have 6 as input and 1 as final output</font>\n",
    "* <font size=4>In the last column of the table you can see how layers are interconnected.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 10.\n",
    "\n",
    "# finalizing and configuring the model\n",
    "# some parameters for configuration:\n",
    "\n",
    "# weights for forest attributes\n",
    "# here we can set how much each forest attribute is affecting the overall accuracy score\n",
    "# the order is the same as for.attrs <- c(\"v\",\"h\",\"d\")\n",
    "# can be experimented with (e.g. c(0.7,0.15,0.15))\n",
    "preds.w <- c(0.6,0.2,0.2)\n",
    "\n",
    "# the optimizer function to be used (see the Optimizers section of 02_Simple_Neural_Networks)\n",
    "# (for further options go to https://keras.rstudio.com/reference/index.html#section-optimizers)\n",
    "opt <- \"adam\"\n",
    "# opt <- \"rmsprop\"\n",
    "\n",
    "# loss function to be used (see the Loss section of 02_Simple_Neural_Networks)\n",
    "# (for further options go to https://keras.rstudio.com/reference/index.html#section-losses)\n",
    "# Mean Squared Error is considered to be a good choice for regression problems and shouldn't be changed\n",
    "loss <- \"mean_squared_error\"\n",
    "\n",
    "# compiling the model\n",
    "tf.model %>% compile(\n",
    "  optimizer=opt,\n",
    "  loss=loss,\n",
    "  loss_weights=preds.w,\n",
    ")\n",
    "\n",
    "cat(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>We are going to train our model in the cell below. Short explanation of the parameters used:</font>\n",
    "* <font size=4><b>early.stop</b>: as discussed in the previous notebook, overfitting needs to be taken care of. One way to do it is to stop the training, when the accuracy of predictions of the validation data doesn't improve anymore. In the function callback_early_stopping we define the accuracy measure monitored and the amount of iterations after which the training process is going to be stopped if no improvement happens. The model tends to \"learn\" the training data and seemingly improves all the time, but the model is not going to perform well on the validation and test data. This means the model is not <b>generalizable</b> if it is overfitted.</font>\n",
    "* <font size=4><b>object</b>: model to train</font>\n",
    "* <font size=4><b>x</b>: training data (in our case the table of features)</font>\n",
    "* <font size=4><b>y</b>: target data (in our case the table of forest attributes)</font>\n",
    "* <font size=4><b>batch_size</b>: number of samples fed into the network at once (if this number is smaller than the total amount of samples, samples are selected randomly from the training data)</font>\n",
    "* <font size=4><b>epochs</b>: number of training iterations</font>\n",
    "* <font size=4><b>validation_data</b>: validation data to be used to evaluate the performance of the model (includes feature table and forest attributes)</font>\n",
    "* <font size=4><b>verbose</b>: should the progress be displayed during training? (0 = silent, 1 = progress bar, 2 = one line per epoch)<br>In the current setup the progress bar doesn't work, progress can be plotted after training is finished.</font>\n",
    "* <font size=4><b>callbacks</b>: list of functions to be executed during training</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11.\n",
    "\n",
    "# parameters for fit function\n",
    "patience=20\n",
    "batch_size=25\n",
    "epochs=200\n",
    "\n",
    "# train the model\n",
    "early.stop <- callback_early_stopping(monitor=\"val_loss\",patience=patience)\n",
    "# fit the model (same as train the model)\n",
    "history <- fit(object=tf.model,x=train.data,y=train.labels,batch_size=batch_size,\n",
    "               epochs=epochs,validation_data=list(val.data,val.labels),\n",
    "               verbose=2,callbacks=list(early.stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12.\n",
    "\n",
    "# plotting the training history\n",
    "# right click on the picture and select \"Open image in new tab\"\n",
    "# the number of epochs needs to be fixed when early stopping is used\n",
    "history$params$epochs <- length(history$metrics$loss)\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>As you can see the training stops before it would reach the maximum amount of epochs. The red dots representing the prediction error of the training set show a decrease throughout the training but the blue ones (validation error) either unsteadily jump up and down, remain approximately the same or even increase as training progresses. This shows that overfitting was taking place during the training and it was necessary to end the training early.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 13.\n",
    "# calculating error estimates, evaluating model performance\n",
    "\n",
    "# calculating predictions with the trained model\n",
    "train.predictions <- tf.model %>% predict(train.data); train.predictions <- as.data.frame(Reduce(cbind,train.predictions))\n",
    "val.predictions <- tf.model %>% predict(val.data); val.predictions <- as.data.frame(Reduce(cbind,val.predictions))\n",
    "test.predictions <- tf.model %>% predict(test.data); test.predictions <- as.data.frame(Reduce(cbind,test.predictions))\n",
    "\n",
    "# de-scaling predictions (when forest attribute data is scaled in the model, the predictions are\n",
    "# going to be scaled as well and need to be de-scaled using the same method used for scaling the \n",
    "# original forest attributes)\n",
    "train.predictions <- sapply(1:ncol(train.predictions),function(i) (train.predictions[i]*sd.train[i])+mean.train[i])\n",
    "train.predictions <- as.data.frame(do.call(cbind,train.predictions))\n",
    "\n",
    "val.predictions <- sapply(1:ncol(val.predictions),function(i) (val.predictions[i]*sd.train[i])+mean.train[i])\n",
    "val.predictions <- as.data.frame(do.call(cbind,val.predictions))\n",
    "\n",
    "test.predictions <- sapply(1:ncol(test.predictions),function(i) (test.predictions[i]*sd.train[i])+mean.train[i])\n",
    "test.predictions <- as.data.frame(do.call(cbind,test.predictions))\n",
    "\n",
    "# calculating relative RMSE and bias for all datasets using predifened functions (see cell 6.)\n",
    "train.rmse <- rel.rmse(sp.data.train,train.predictions)\n",
    "train.bias <- rel.bias(sp.data.train,train.predictions)\n",
    "\n",
    "val.rmse <- rel.rmse(sp.data.val,val.predictions)\n",
    "val.bias <- rel.bias(sp.data.val,val.predictions)\n",
    "\n",
    "test.rmse <- rel.rmse(sp.data.test,test.predictions)\n",
    "test.bias <- rel.bias(sp.data.test,test.predictions)\n",
    "\n",
    "# printing results\n",
    "results <- rbind(train.rmse,val.rmse,test.rmse)\n",
    "row.names(results) <- c(\"training RMSE %\",\"validation RMSE %\",\"test RMSE %\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Looking at the results you will find</font>\n",
    "* <font size=4>Training errors tend to be lower than validation/test errors. The model is \"learning\" the training data, therefore its performance with the training data gets better, but it doesn't perform as good on other datasets. The model is not or poorly generalizable.</font>\n",
    "* <font size=4>The performance of the model on the validation and test sets can be random. Sometimes you will see that test errors are lower than validation errors, sometimes the other way around.</font>\n",
    "* <font size=4>Most important to us is that the model performs relatively well on the test data. The test dataset is completely new to the model and therefore shows how well the model can be applied to new data. It is also possible to further train the model with new data.</font>\n",
    "\n",
    "<font size=4><b>Note the results in a text editor or Excel sheet along with the parameters used.</b> You can compare the performance of different parameter combinations.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>It is important to mention that <b>the model is trained \"in place\"</b>. Iteration after iteration the parameters of the model are changed hence the object called tf.model changes as well. After training tf.model can be saved and reused for making predictions for new data, training the model further with new data, training part of the model with new data. It is also important to know that <b>there is a lot of randomness involved when working with Neural Networks</b>. This means that generally two training runs with the same parameters will never give the exact same results unless randomness is being dealt with (randomness is not removed in this exercise). You can do a small experiment and run the training twice with the same parameters then look at the results.<br>In the following code cells you will see how the model can be saved and reloaded into R.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 14.\n",
    "\n",
    "# if you are satisfied with the results you can save the model for later use\n",
    "# it is generally useful to save the model using a name that refers to the training\n",
    "# parameters like batch size, activation function, etc.\n",
    "# below the name has the following tags separated with _:\n",
    "# optimization funciton, activation function, batch size, weights for froest attributes (leaving out zeros)\n",
    "out.name <- \"adam_swish_bs25_6.2.2.h5\"\n",
    "tf.model %>% save_model_hdf5(\"out.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15.\n",
    "\n",
    "# this is how you can load the model later\n",
    "# if you have used a custom object (e.g. swish_activation) use the custom_objects parameter\n",
    "new_model <- load_model_hdf5(out.name,custom_objects=c(\"python_function\"=swish_activation))\n",
    "\n",
    "# if no custom objects were used\n",
    "# new_model <- load_model_hdf5(\"my_model.h5\")\n",
    "\n",
    "summary(new_model)\n",
    "\n",
    "# for further information visit:\n",
    "# https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_save_and_restore/\n",
    "rm(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=4>Let's clean up after the training is done, results and model is saved. Without doing so errors might occur during consecutive trainings.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16.\n",
    "\n",
    "# let's clean up after training; if this is not done errors will occur\n",
    "# when you try to start building and training a new model\n",
    "rm(tf.model)\n",
    "k_clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<font size=5><b>Exercise</b></font><br><br>\n",
    "\n",
    "<font size=4>Try out different options for some parameters (optimization and activation function, number of neurons in the hidden layer, batch size, weights for forest attributes, number of epochs). Best practice is to change one parameter at the time, compare the results to the previous ones and so on. <b>Whenever you change some parameter(s) run first cell 16. in order to reset the session and then run everything from cell 7. to cell 13. or 14. if you want to save the model.</b></font><br>\n",
    "\n",
    "* <font size=4>Go back to cell 7. and try other options for number of neurons in the hidden layer</font><br><br>\n",
    "* <font size=4>Go back to cell 8. and try RELU activation (you can also try \"elu\" instead of \"relu\")</font>\n",
    "```R\n",
    "layer_dense(units=n.neur,activation=\"relu\") %>%\n",
    "# layer_dense(units=n.neur,activation=swish_activation) %>%\n",
    "```\n",
    "* <font size=4>Go back to cell 10. and try another set of weights for forest attributes</font>\n",
    "```R\n",
    "# can be experimented with (e.g. c(0.7,0.15,0.15))\n",
    "preds.w <- c(0.7,0.15,0.15)\n",
    "```\n",
    "* <font size=4>Go back to cell 10. and try some other optimizer function</font>\n",
    "```R\n",
    "# opt <- \"adam\"\n",
    "opt <- \"rmsprop\"\n",
    "```\n",
    "* <font size=4>Go back to cell 11. and try some other options for <b>batch size</b> (shouldn't be set to more than 1044 that is the number of samples in the training data), <b>number of epochs</b> (the bigger number the longer the training will run), <b>patience</b> (you can also try to set it to the same value as the number of epochs; this way no early stopping is done)</font>\n",
    "```R\n",
    "# parameters for fit function\n",
    "patience=20\n",
    "batch_size=25\n",
    "epochs=200\n",
    "```\n",
    "\n",
    "<font size=4><b>Remember to change the file name for your new model in cell 14., otherwise the already existing file will be replaced!</b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
